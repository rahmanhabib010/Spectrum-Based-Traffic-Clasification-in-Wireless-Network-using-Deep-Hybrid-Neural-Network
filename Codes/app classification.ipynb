{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75e0d017",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "\n",
    "#design network\n",
    "from keras.layers import Conv1D, MaxPooling1D, Flatten, Dense, Input, Conv2D\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Flatten, Dense, Dropout, Average, Add, MaxPooling2D, SimpleRNN, Concatenate, GlobalAveragePooling2D, Reshape, GRU\n",
    "from keras import Model\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "325cea5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from helpers import pre_processing_wlan_utils as preprocess_utils\n",
    "# from helpers import classifier_wlan_spectral_utils as classifier_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f162fe6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# # importlib.reload(tr_models)\n",
    "# importlib.reload(classifier_utils)\n",
    "# importlib.reload(preprocess_utils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "75d12544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# task = 'app'\n",
    "# label = preprocess_utils.label_index[task]\n",
    "# num_classes = preprocess_utils.num_classes[task]\n",
    "# labels_string = preprocess_utils.labels_string[task]\n",
    "# print(\"Label id: \", label)\n",
    "# print(\"Num classes in that label: \", num_classes)\n",
    "# print(\"Labels: \", labels_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf4dd86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if (task == 'app') or (task == 'app-type'):\n",
    "#     num_classes = num_classes-1\n",
    "#     labels_string = labels_string[0:num_classes]\n",
    "#     print(\"Label id: \", label)\n",
    "#     print(\"Num classes in that label: \", num_classes)\n",
    "#     print(\"Labels: \", labels_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90a2c379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seq_length = 3000\n",
    "\n",
    "# #Set type of padding. \n",
    "# padding = 'post'\n",
    "\n",
    "# #Set path to dataset folder. All the files from the dataset can be downloaded from https://zenodo.org/record/5208201\n",
    "# dataset_folder = './waveforms/'\n",
    "\n",
    "# #Set name of dataset file. In this case we are using once of the balanced dataset (filename_balanced.mat)\n",
    "# dataset_filename = 'waveforms_2G_n_SNR_'+task+'_balanced.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bace036",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Xraw, Yraw = classifier_utils.get_raw_xy_spectrum(dataset_folder,dataset_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0078b0bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Padding/Truncating sequence to a length of \",str(seq_length))\n",
    "#X = classifier_utils.pad_or_trunc_x_and_scale(Xraw, seq_length, padding, scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49d9671c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(X[0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f332c764",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7eb93b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Generate one-shot labels\")\n",
    "#Y = classifier_utils.get_one_hot_labels(Yraw, num_classes, label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94c42a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71603, 2, 3000)\n",
      "(71603, 7)\n"
     ]
    }
   ],
   "source": [
    "# from numpy import savez_compressed\n",
    "# savez_compressed('x_app.npz', X)\n",
    "# savez_compressed('y_app.npz', Y)\n",
    "\n",
    "X= np.load('x_app.npz')\n",
    "X=X['arr_0']\n",
    "Y= np.load('y_app.npz')\n",
    "Y=Y['arr_0']\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "262537ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3bda2aeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seed = 42\n",
    "# print(\"Performing data splitting\")\n",
    "# X_train, X_val, X_test, Y_train, Y_val, Y_test = classifier_utils.get_xy_4_training(X,Y,seed)\n",
    "# print(X_train.shape,X_val.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab7f828c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape((57282,3000,2,1))\n",
    "# X_val=X_val.reshape((7160,3000,2,1))\n",
    "X_test=X_test.reshape((14321,3000,2,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07ac5558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(xin,f,k,p,d):\n",
    "    x=Conv2D(f,(k,1), activation=\"relu\", padding='same', kernel_initializer=\"glorot_normal\")(xin)\n",
    "    x=MaxPooling2D((p,p), padding='same')(x)\n",
    "    x=Dropout(d)(x)\n",
    "    x=BatchNormalization(axis=-1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9895db25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_block(xin, n, d):\n",
    "    x=Dense(n, activation='relu')(xin)\n",
    "    x=Dropout(d)(x)\n",
    "    x=BatchNormalization(axis=-1)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "962c26f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xin= Input(shape=(3000,2,1))\n",
    "# x1=conv_block(xin,64,32,2,0.1)\n",
    "# x2=conv_block(x1,64,32,2,0.1)\n",
    "# xres1=Concatenate(axis=1)([x1,x2])\n",
    "# x3=conv_block(xres1,64,32,2,0.1)\n",
    "# xres2=Concatenate(axis=1)([x3,xres1])\n",
    "# x4=conv_block(xres2,64,32,2,0.1)\n",
    "# xres3=Concatenate(axis=1)([x4,xres2])\n",
    "# x5=conv_block(xres3,64,32,2,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "da1e76cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 3000, 2, 1)  0           []                               \n",
      "                                ]                                                                 \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)                (None, 3000, 2, 64)  2112        ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " max_pooling2d (MaxPooling2D)   (None, 1500, 1, 64)  0           ['conv2d[0][0]']                 \n",
      "                                                                                                  \n",
      " dropout (Dropout)              (None, 1500, 1, 64)  0           ['max_pooling2d[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization (BatchNorm  (None, 1500, 1, 64)  256        ['dropout[0][0]']                \n",
      " alization)                                                                                       \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)              (None, 1500, 1, 64)  131136      ['batch_normalization[0][0]']    \n",
      "                                                                                                  \n",
      " max_pooling2d_1 (MaxPooling2D)  (None, 750, 1, 64)  0           ['conv2d_1[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 750, 1, 64)   0           ['max_pooling2d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 750, 1, 64)  256         ['dropout_1[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)              (None, 750, 1, 64)   131136      ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_2 (MaxPooling2D)  (None, 375, 1, 64)  0           ['conv2d_2[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_2 (Dropout)            (None, 375, 1, 64)   0           ['max_pooling2d_2[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 375, 1, 64)  256         ['dropout_2[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 375, 1, 64)   131136      ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_3 (MaxPooling2D)  (None, 188, 1, 64)  0           ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_3 (Dropout)            (None, 188, 1, 64)   0           ['max_pooling2d_3[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 188, 1, 64)  256         ['dropout_3[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 188, 1, 64)   131136      ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_4 (MaxPooling2D)  (None, 94, 1, 64)   0           ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_4 (Dropout)            (None, 94, 1, 64)    0           ['max_pooling2d_4[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 94, 1, 64)   256         ['dropout_4[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 94, 1, 64)    131136      ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_5 (MaxPooling2D)  (None, 47, 1, 64)   0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_5 (Dropout)            (None, 47, 1, 64)    0           ['max_pooling2d_5[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 47, 1, 64)   256         ['dropout_5[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)              (None, 47, 1, 64)    131136      ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      " max_pooling2d_6 (MaxPooling2D)  (None, 24, 1, 64)   0           ['conv2d_6[0][0]']               \n",
      "                                                                                                  \n",
      " dropout_6 (Dropout)            (None, 24, 1, 64)    0           ['max_pooling2d_6[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_6 (BatchNo  (None, 24, 1, 64)   256         ['dropout_6[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 71, 1, 64)    0           ['batch_normalization_5[0][0]',  \n",
      "                                                                  'batch_normalization_6[0][0]']  \n",
      "                                                                                                  \n",
      " reshape (Reshape)              (None, 71, 64)       0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " gru (GRU)                      (None, 20)           5160        ['reshape[0][0]']                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1024)         21504       ['gru[0][0]']                    \n",
      "                                                                                                  \n",
      " dropout_7 (Dropout)            (None, 1024)         0           ['dense[0][0]']                  \n",
      "                                                                                                  \n",
      " batch_normalization_7 (BatchNo  (None, 1024)        4096        ['dropout_7[0][0]']              \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 7)            7175        ['batch_normalization_7[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 828,655\n",
      "Trainable params: 825,711\n",
      "Non-trainable params: 2,944\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xin= Input(shape=(3000,2,1))\n",
    "x1=conv_block(xin,64,32,2,0.1)\n",
    "x2=conv_block(x1,64,32,2,0.1)\n",
    "x3=conv_block(x2,64,32,2,0.1)\n",
    "x4=conv_block(x3,64,32,2,0.1)\n",
    "x5=conv_block(x4,64,32,2,0.1)\n",
    "x6=conv_block(x5,64,32,2,0.1)\n",
    "x7=conv_block(x6,64,32,2,0.1)\n",
    "x=Concatenate(axis=1)([x6, x7])\n",
    "\n",
    "x=Reshape((71,64), input_shape=(71, 1, 64))(x)\n",
    "\n",
    "x=GRU(20)(x)\n",
    "\n",
    "# # # x=Dropout(.1)(x)\n",
    "\n",
    "x=clf_block(x,1024,0.1)\n",
    "# # x=clf_block(x,128,0.1)\n",
    "x=Dense(7, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=xin, outputs=x)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6896b55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=opt, \n",
    "                loss='categorical_crossentropy',\n",
    "                metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cf2461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "896/896 [==============================] - 37s 34ms/step - loss: 1.5684 - accuracy: 0.3812 - val_loss: 1.2639 - val_accuracy: 0.4998\n",
      "Epoch 2/100\n",
      "896/896 [==============================] - 29s 33ms/step - loss: 1.0826 - accuracy: 0.5763 - val_loss: 1.0233 - val_accuracy: 0.5787\n",
      "Epoch 3/100\n",
      "171/896 [====>.........................] - ETA: 22s - loss: 0.9629 - accuracy: 0.6153"
     ]
    }
   ],
   "source": [
    "EPOCHS = 100\n",
    "history = model.fit(X_train, y_train, epochs=EPOCHS, validation_data = (X_test,y_test),batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b07af574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(history,X_test,y_test,model):\n",
    "    scores = model.evaluate((X_test),y_test, verbose=1)\n",
    "    print(\"Accuracy: %.2f%%\" % (scores[1]*100))\n",
    "    \n",
    "    print(history)\n",
    "    fig1, ax_acc = plt.subplots(figsize=(8, 6))\n",
    "    \n",
    "    ax_acc.tick_params(axis=\"y\",direction=\"in\",which=\"both\",labelsize=13)\n",
    "    ax_acc.tick_params(axis=\"x\",direction=\"in\",which=\"both\",labelsize=13)\n",
    "    plt.plot(history.history['accuracy'], color='r', linewidth=2)\n",
    "    plt.plot(history.history['val_accuracy'], color='b', linewidth=2)\n",
    "    \n",
    "    csfont = {'fontname':'Times New Roman'}\n",
    "    \n",
    "    plt.xlabel('Epoch',fontsize=17,**csfont)\n",
    "    plt.ylabel('Accuracy',fontsize=17,**csfont)\n",
    "#     plt.title('Model - Accuracy')\n",
    "    plt.legend(['Training', 'Validation'], loc='lower right',prop={\"family\":'Times New Roman', \"size\":17})\n",
    "#     plt.show()\n",
    "    plt.savefig('app.png')\n",
    "    \n",
    "    \n",
    "#     fig2, ax_loss = plt.subplots()\n",
    "#     plt.xlabel('Epoch')\n",
    "#     plt.ylabel('Loss')\n",
    "#     plt.title('Model- Loss')\n",
    "#     plt.legend(['Training', 'Validation'], loc='upper right')\n",
    "#     plt.plot(history.history['loss'])\n",
    "#     plt.plot(history.history['val_loss'])\n",
    "#     plt.show()\n",
    "#     target_names=['0','1','2','3','4','5','6']\n",
    "    \n",
    "    \n",
    "    \n",
    "    y_true=[]\n",
    "    for element in y_test:\n",
    "        y_true.append(np.argmax(element))\n",
    "    prediction_proba=model.predict(X_test)\n",
    "    prediction=np.argmax(prediction_proba,axis=1)\n",
    "    cnf_matrix = confusion_matrix(y_true, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce35e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "evaluate_model(history,X_test,y_test,model)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "151a6fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(figsize=(10,8))\n",
    "#     plt.rcParams[\"font.family\"] = \"Times New Roman\"\n",
    "    \n",
    "    ax.tick_params(axis=\"y\",direction=\"in\",which=\"both\")\n",
    "    ax.tick_params(axis=\"x\",direction=\"in\",which=\"both\")\n",
    "    \n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "#     plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes,fontsize=12)\n",
    "    plt.yticks(tick_marks, classes,fontsize=12)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\",fontsize=15)\n",
    "\n",
    "#     plt.tight_layout()\n",
    "    csfont = {'fontname':'Times New Roman'}\n",
    "        \n",
    "    plt.ylabel('True label', labelpad=15,fontsize=15,**csfont)\n",
    "    plt.xlabel('Predicted label', labelpad=15,fontsize=15,**csfont)\n",
    "    plt.savefig('app CM.png')\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "cnf_matrix = confusion_matrix(y_test.argmax(axis=1), y_pred.argmax(axis=1))\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot non-normalized confusion matrix\n",
    "# plt.figure(figsize=(10, 10))\n",
    "plot_confusion_matrix(cnf_matrix, classes=[\"Spotify\", \"Tunein\", \"Gpodcast\", \"Youtube\", \"Netflix\", \"Twitch\", \"No-app\",])\n",
    "# plt.show()\n",
    "# plt.savefig('app CM.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e83888f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test.argmax(axis=1), y_pred.argmax(axis=1), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76425d07",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
